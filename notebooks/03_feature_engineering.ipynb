{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cba3cd",
   "metadata": {},
   "source": [
    "# ⚙️ TCS Stock - Advanced Feature Engineering\n",
    "\n",
    "## 🎯 Objective\n",
    "Create comprehensive technical indicators and features for machine learning models:\n",
    "- **Technical Indicators**: RSI, MACD, Bollinger Bands, Stochastic\n",
    "- **Moving Averages**: Simple, Exponential, Weighted\n",
    "- **Volatility Measures**: ATR, Bollinger Band Width, Historical Volatility\n",
    "- **Price Features**: Returns, Gaps, Price Channels\n",
    "- **Volume Features**: Volume indicators, Money Flow\n",
    "- **Time-based Features**: Seasonality, Cyclical patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Technical Analysis\n",
    "try:\n",
    "    import talib\n",
    "    TALIB_AVAILABLE = True\n",
    "    print('✅ TA-Lib available for advanced technical indicators')\n",
    "except ImportError:\n",
    "    TALIB_AVAILABLE = False\n",
    "    print('⚠️ TA-Lib not available - using manual calculations')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print('🎯 TCS STOCK - ADVANCED FEATURE ENGINEERING')\n",
    "print('='*60)\n",
    "print('✅ All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48649a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data from previous notebook\n",
    "print('📁 Loading cleaned TCS stock data...')\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../data/TCS_stock_cleaned.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "    print(f'✅ Data loaded successfully: {df.shape}')\n",
    "except FileNotFoundError:\n",
    "    print('⚠️ Cleaned data not found, loading original data...')\n",
    "    df = pd.read_csv('../data/TCS_stock_history.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "    print(f'✅ Original data loaded: {df.shape}')\n",
    "\n",
    "# Display basic info\n",
    "print(f'📅 Date range: {df[\"Date\"].min().date()} to {df[\"Date\"].max().date()}')\n",
    "print(f'📊 Columns: {list(df.columns)}')\n",
    "print(f'🔍 Shape: {df.shape}')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acedfc5",
   "metadata": {},
   "source": [
    "## 💰 Price-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('💰 CREATING PRICE-BASED FEATURES')\n",
    "print('='*40)\n",
    "\n",
    "# Create a copy for feature engineering\n",
    "df_features = df.copy()\n",
    "\n",
    "# 1. Basic Price Features\n",
    "print('1. 📊 Basic Price Features:')\n",
    "df_features['Price_Range'] = df_features['High'] - df_features['Low']\n",
    "df_features['Price_Range_Pct'] = (df_features['Price_Range'] / df_features['Close']) * 100\n",
    "df_features['Open_Close_Pct'] = ((df_features['Close'] - df_features['Open']) / df_features['Open']) * 100\n",
    "df_features['High_Low_Pct'] = ((df_features['High'] - df_features['Low']) / df_features['Close']) * 100\n",
    "print('   ✅ Price range, Open-Close %, High-Low % created')\n",
    "\n",
    "# 2. Returns Features\n",
    "print('2. 📈 Returns Features:')\n",
    "df_features['Daily_Return'] = df_features['Close'].pct_change() * 100\n",
    "df_features['Log_Return'] = np.log(df_features['Close'] / df_features['Close'].shift(1)) * 100\n",
    "\n",
    "# Multi-period returns\n",
    "for period in [2, 3, 5, 10, 20]:\n",
    "    df_features[f'Return_{period}d'] = df_features['Close'].pct_change(period) * 100\n",
    "print('   ✅ Daily, log, and multi-period returns created')\n",
    "\n",
    "# 3. Price Position Features\n",
    "print('3. 🎯 Price Position Features:')\n",
    "for window in [10, 20, 50]:\n",
    "    rolling_high = df_features['High'].rolling(window=window).max()\n",
    "    rolling_low = df_features['Low'].rolling(window=window).min()\n",
    "    df_features[f'Price_Position_{window}d'] = ((df_features['Close'] - rolling_low) / (rolling_high - rolling_low)) * 100\n",
    "print('   ✅ Price position within rolling windows created')\n",
    "\n",
    "# 4. Gap Analysis\n",
    "print('4. 📊 Gap Analysis:')\n",
    "df_features['Gap'] = df_features['Open'] - df_features['Close'].shift(1)\n",
    "df_features['Gap_Pct'] = (df_features['Gap'] / df_features['Close'].shift(1)) * 100\n",
    "df_features['Gap_Up'] = (df_features['Gap_Pct'] > 0.5).astype(int)\n",
    "df_features['Gap_Down'] = (df_features['Gap_Pct'] < -0.5).astype(int)\n",
    "print('   ✅ Gap analysis features created')\n",
    "\n",
    "print(f'\\n📊 Current features count: {df_features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0eb90d",
   "metadata": {},
   "source": [
    "## 📈 Moving Averages & Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('📈 CREATING MOVING AVERAGES & TREND FEATURES')\n",
    "print('='*50)\n",
    "\n",
    "# 1. Simple Moving Averages\n",
    "print('1. 📊 Simple Moving Averages:')\n",
    "ma_periods = [5, 10, 20, 50, 100, 200]\n",
    "for period in ma_periods:\n",
    "    df_features[f'SMA_{period}'] = df_features['Close'].rolling(window=period).mean()\n",
    "    df_features[f'SMA_{period}_ratio'] = df_features['Close'] / df_features[f'SMA_{period}']\n",
    "    df_features[f'SMA_{period}_distance'] = ((df_features['Close'] - df_features[f'SMA_{period}']) / df_features[f'SMA_{period}']) * 100\n",
    "print(f'   ✅ SMA for periods {ma_periods} created')\n",
    "\n",
    "# 2. Exponential Moving Averages\n",
    "print('2. 📊 Exponential Moving Averages:')\n",
    "ema_periods = [12, 26, 50]\n",
    "for period in ema_periods:\n",
    "    df_features[f'EMA_{period}'] = df_features['Close'].ewm(span=period).mean()\n",
    "    df_features[f'EMA_{period}_ratio'] = df_features['Close'] / df_features[f'EMA_{period}']\n",
    "print(f'   ✅ EMA for periods {ema_periods} created')\n",
    "\n",
    "# 3. Moving Average Convergence Divergence (MACD)\n",
    "print('3. 📊 MACD Indicators:')\n",
    "if TALIB_AVAILABLE:\n",
    "    macd, macd_signal, macd_hist = talib.MACD(df_features['Close'].values)\n",
    "    df_features['MACD'] = macd\n",
    "    df_features['MACD_Signal'] = macd_signal\n",
    "    df_features['MACD_Histogram'] = macd_hist\n",
    "else:\n",
    "    # Manual MACD calculation\n",
    "    ema_12 = df_features['Close'].ewm(span=12).mean()\n",
    "    ema_26 = df_features['Close'].ewm(span=26).mean()\n",
    "    df_features['MACD'] = ema_12 - ema_26\n",
    "    df_features['MACD_Signal'] = df_features['MACD'].ewm(span=9).mean()\n",
    "    df_features['MACD_Histogram'] = df_features['MACD'] - df_features['MACD_Signal']\n",
    "\n",
    "# MACD derived features\n",
    "df_features['MACD_Bullish'] = (df_features['MACD'] > df_features['MACD_Signal']).astype(int)\n",
    "df_features['MACD_Cross_Up'] = ((df_features['MACD'] > df_features['MACD_Signal']) & \n",
    "                               (df_features['MACD'].shift(1) <= df_features['MACD_Signal'].shift(1))).astype(int)\n",
    "print('   ✅ MACD and derived signals created')\n",
    "\n",
    "# 4. Moving Average Cross Signals\n",
    "print('4. 📊 Moving Average Cross Signals:')\n",
    "df_features['SMA_Cross_5_20'] = (df_features['SMA_5'] > df_features['SMA_20']).astype(int)\n",
    "df_features['SMA_Cross_20_50'] = (df_features['SMA_20'] > df_features['SMA_50']).astype(int)\n",
    "df_features['Golden_Cross'] = ((df_features['SMA_50'] > df_features['SMA_200']) &\n",
    "                              (df_features['SMA_50'].shift(1) <= df_features['SMA_200'].shift(1))).astype(int)\n",
    "df_features['Death_Cross'] = ((df_features['SMA_50'] < df_features['SMA_200']) &\n",
    "                             (df_features['SMA_50'].shift(1) >= df_features['SMA_200'].shift(1))).astype(int)\n",
    "print('   ✅ Moving average cross signals created')\n",
    "\n",
    "print(f'\\n📊 Current features count: {df_features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319d87d",
   "metadata": {},
   "source": [
    "## 🔧 Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('🔧 CREATING TECHNICAL INDICATORS')\n",
    "print('='*40)\n",
    "\n",
    "# 1. Relative Strength Index (RSI)\n",
    "print('1. 📊 RSI Indicators:')\n",
    "def calculate_rsi(prices, window=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "if TALIB_AVAILABLE:\n",
    "    df_features['RSI_14'] = talib.RSI(df_features['Close'].values, timeperiod=14)\n",
    "    df_features['RSI_21'] = talib.RSI(df_features['Close'].values, timeperiod=21)\n",
    "else:\n",
    "    df_features['RSI_14'] = calculate_rsi(df_features['Close'], 14)\n",
    "    df_features['RSI_21'] = calculate_rsi(df_features['Close'], 21)\n",
    "\n",
    "# RSI derived features\n",
    "df_features['RSI_Overbought'] = (df_features['RSI_14'] > 70).astype(int)\n",
    "df_features['RSI_Oversold'] = (df_features['RSI_14'] < 30).astype(int)\n",
    "print('   ✅ RSI and derived signals created')\n",
    "\n",
    "# 2. Bollinger Bands\n",
    "print('2. 📊 Bollinger Bands:')\n",
    "bb_period = 20\n",
    "bb_std = 2\n",
    "\n",
    "if TALIB_AVAILABLE:\n",
    "    bb_upper, bb_middle, bb_lower = talib.BBANDS(df_features['Close'].values, \n",
    "                                                timeperiod=bb_period, nbdevup=bb_std, nbdevdn=bb_std)\n",
    "    df_features['BB_Upper'] = bb_upper\n",
    "    df_features['BB_Middle'] = bb_middle\n",
    "    df_features['BB_Lower'] = bb_lower\n",
    "else:\n",
    "    df_features['BB_Middle'] = df_features['Close'].rolling(window=bb_period).mean()\n",
    "    bb_std_dev = df_features['Close'].rolling(window=bb_period).std()\n",
    "    df_features['BB_Upper'] = df_features['BB_Middle'] + (bb_std_dev * bb_std)\n",
    "    df_features['BB_Lower'] = df_features['BB_Middle'] - (bb_std_dev * bb_std)\n",
    "\n",
    "# Bollinger Bands derived features\n",
    "df_features['BB_Width'] = df_features['BB_Upper'] - df_features['BB_Lower']\n",
    "df_features['BB_Position'] = ((df_features['Close'] - df_features['BB_Lower']) / \n",
    "                             (df_features['BB_Upper'] - df_features['BB_Lower'])) * 100\n",
    "df_features['BB_Squeeze'] = (df_features['BB_Width'] < df_features['BB_Width'].rolling(window=20).mean()).astype(int)\n",
    "df_features['BB_Breakout_Up'] = (df_features['Close'] > df_features['BB_Upper']).astype(int)\n",
    "df_features['BB_Breakout_Down'] = (df_features['Close'] < df_features['BB_Lower']).astype(int)\n",
    "print('   ✅ Bollinger Bands and derived features created')\n",
    "\n",
    "# 3. Stochastic Oscillator\n",
    "print('3. 📊 Stochastic Oscillator:')\n",
    "def calculate_stochastic(high, low, close, k_period=14, d_period=3):\n",
    "    lowest_low = low.rolling(window=k_period).min()\n",
    "    highest_high = high.rolling(window=k_period).max()\n",
    "    k_percent = ((close - lowest_low) / (highest_high - lowest_low)) * 100\n",
    "    d_percent = k_percent.rolling(window=d_period).mean()\n",
    "    return k_percent, d_percent\n",
    "\n",
    "if TALIB_AVAILABLE:\n",
    "    stoch_k, stoch_d = talib.STOCH(df_features['High'].values, df_features['Low'].values, \n",
    "                                  df_features['Close'].values)\n",
    "    df_features['Stoch_K'] = stoch_k\n",
    "    df_features['Stoch_D'] = stoch_d\n",
    "else:\n",
    "    df_features['Stoch_K'], df_features['Stoch_D'] = calculate_stochastic(\n",
    "        df_features['High'], df_features['Low'], df_features['Close'])\n",
    "\n",
    "# Stochastic derived features\n",
    "df_features['Stoch_Overbought'] = (df_features['Stoch_K'] > 80).astype(int)\n",
    "df_features['Stoch_Oversold'] = (df_features['Stoch_K'] < 20).astype(int)\n",
    "print('   ✅ Stochastic Oscillator created')\n",
    "\n",
    "# 4. Average True Range (ATR)\n",
    "print('4. 📊 Average True Range:')\n",
    "def calculate_atr(high, low, close, period=14):\n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - close.shift(1))\n",
    "    tr3 = abs(low - close.shift(1))\n",
    "    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    atr = true_range.rolling(window=period).mean()\n",
    "    return atr\n",
    "\n",
    "if TALIB_AVAILABLE:\n",
    "    df_features['ATR_14'] = talib.ATR(df_features['High'].values, df_features['Low'].values, \n",
    "                                     df_features['Close'].values, timeperiod=14)\n",
    "else:\n",
    "    df_features['ATR_14'] = calculate_atr(df_features['High'], df_features['Low'], df_features['Close'])\n",
    "\n",
    "# ATR derived features\n",
    "df_features['ATR_Ratio'] = df_features['ATR_14'] / df_features['Close'] * 100\n",
    "print('   ✅ ATR and ratio created')\n",
    "\n",
    "print(f'\\n📊 Current features count: {df_features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cb83a",
   "metadata": {},
   "source": [
    "## 📊 Volume-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('📊 CREATING VOLUME-BASED FEATURES')\n",
    "print('='*40)\n",
    "\n",
    "if 'Volume' in df_features.columns:\n",
    "    # 1. Volume Moving Averages\n",
    "    print('1. 📊 Volume Moving Averages:')\n",
    "    volume_periods = [10, 20, 50]\n",
    "    for period in volume_periods:\n",
    "        df_features[f'Volume_SMA_{period}'] = df_features['Volume'].rolling(window=period).mean()\n",
    "        df_features[f'Volume_Ratio_{period}'] = df_features['Volume'] / df_features[f'Volume_SMA_{period}']\n",
    "    print(f'   ✅ Volume SMA and ratios for periods {volume_periods} created')\n",
    "    \n",
    "    # 2. Volume-Price Features\n",
    "    print('2. 📊 Volume-Price Features:')\n",
    "    df_features['Volume_Price'] = df_features['Volume'] * df_features['Close']\n",
    "    df_features['Volume_Weighted_Price'] = (df_features['Volume'] * df_features['Close']).rolling(window=20).sum() / df_features['Volume'].rolling(window=20).sum()\n",
    "    print('   ✅ Volume-weighted features created')\n",
    "    \n",
    "    # 3. On-Balance Volume (OBV)\n",
    "    print('3. 📊 On-Balance Volume:')\n",
    "    if TALIB_AVAILABLE:\n",
    "        df_features['OBV'] = talib.OBV(df_features['Close'].values, df_features['Volume'].values)\n",
    "    else:\n",
    "        # Manual OBV calculation\n",
    "        obv = [0]\n",
    "        for i in range(1, len(df_features)):\n",
    "            if df_features['Close'].iloc[i] > df_features['Close'].iloc[i-1]:\n",
    "                obv.append(obv[-1] + df_features['Volume'].iloc[i])\n",
    "            elif df_features['Close'].iloc[i] < df_features['Close'].iloc[i-1]:\n",
    "                obv.append(obv[-1] - df_features['Volume'].iloc[i])\n",
    "            else:\n",
    "                obv.append(obv[-1])\n",
    "        df_features['OBV'] = obv\n",
    "    \n",
    "    # OBV derived features\n",
    "    df_features['OBV_SMA_20'] = df_features['OBV'].rolling(window=20).mean()\n",
    "    df_features['OBV_Signal'] = (df_features['OBV'] > df_features['OBV_SMA_20']).astype(int)\n",
    "    print('   ✅ OBV and derived signals created')\n",
    "    \n",
    "    # 4. Volume Anomalies\n",
    "    print('4. 📊 Volume Anomalies:')\n",
    "    volume_mean = df_features['Volume'].rolling(window=50).mean()\n",
    "    volume_std = df_features['Volume'].rolling(window=50).std()\n",
    "    df_features['Volume_High_Anomaly'] = (df_features['Volume'] > (volume_mean + 2 * volume_std)).astype(int)\n",
    "    df_features['Volume_Low_Anomaly'] = (df_features['Volume'] < (volume_mean - 2 * volume_std)).astype(int)\n",
    "    print('   ✅ Volume anomaly detection features created')\n",
    "else:\n",
    "    print('⚠️ Volume column not found, skipping volume-based features')\n",
    "\n",
    "print(f'\\n📊 Current features count: {df_features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f3f74",
   "metadata": {},
   "source": [
    "## 📅 Time-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fe23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('📅 CREATING TIME-BASED FEATURES')\n",
    "print('='*40)\n",
    "\n",
    "# 1. Basic Time Features\n",
    "print('1. 📊 Basic Time Features:')\n",
    "df_features['Year'] = df_features['Date'].dt.year\n",
    "df_features['Month'] = df_features['Date'].dt.month\n",
    "df_features['Quarter'] = df_features['Date'].dt.quarter\n",
    "df_features['DayOfWeek'] = df_features['Date'].dt.dayofweek\n",
    "df_features['DayOfMonth'] = df_features['Date'].dt.day\n",
    "df_features['DayOfYear'] = df_features['Date'].dt.dayofyear\n",
    "print('   ✅ Year, month, quarter, day features created')\n",
    "\n",
    "# 2. Cyclical Time Features\n",
    "print('2. 📊 Cyclical Time Features:')\n",
    "df_features['Month_Sin'] = np.sin(2 * np.pi * df_features['Month'] / 12)\n",
    "df_features['Month_Cos'] = np.cos(2 * np.pi * df_features['Month'] / 12)\n",
    "df_features['DayOfWeek_Sin'] = np.sin(2 * np.pi * df_features['DayOfWeek'] / 7)\n",
    "df_features['DayOfWeek_Cos'] = np.cos(2 * np.pi * df_features['DayOfWeek'] / 7)\n",
    "df_features['DayOfYear_Sin'] = np.sin(2 * np.pi * df_features['DayOfYear'] / 365.25)\n",
    "df_features['DayOfYear_Cos'] = np.cos(2 * np.pi * df_features['DayOfYear'] / 365.25)\n",
    "print('   ✅ Cyclical encodings created')\n",
    "\n",
    "# 3. Market Timing Features\n",
    "print('3. 📊 Market Timing Features:')\n",
    "df_features['Is_Monday'] = (df_features['DayOfWeek'] == 0).astype(int)\n",
    "df_features['Is_Friday'] = (df_features['DayOfWeek'] == 4).astype(int)\n",
    "df_features['Is_Month_End'] = (df_features['Date'].dt.is_month_end).astype(int)\n",
    "df_features['Is_Month_Start'] = (df_features['Date'].dt.is_month_start).astype(int)\n",
    "df_features['Is_Quarter_End'] = (df_features['Date'].dt.is_quarter_end).astype(int)\n",
    "print('   ✅ Market timing indicators created')\n",
    "\n",
    "# 4. Lag Features\n",
    "print('4. 📊 Lag Features:')\n",
    "lag_periods = [1, 2, 3, 5, 10]\n",
    "lag_columns = ['Close', 'Volume', 'Daily_Return'] if 'Volume' in df_features.columns else ['Close', 'Daily_Return']\n",
    "\n",
    "for col in lag_columns:\n",
    "    if col in df_features.columns:\n",
    "        for lag in lag_periods:\n",
    "            df_features[f'{col}_Lag_{lag}'] = df_features[col].shift(lag)\n",
    "print(f'   ✅ Lag features for {lag_columns} created')\n",
    "\n",
    "print(f'\\n📊 Current features count: {df_features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526f553",
   "metadata": {},
   "source": [
    "## 🚀 Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ddb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('🚀 CREATING ADVANCED FEATURES')\n",
    "print('='*40)\n",
    "\n",
    "# 1. Volatility Features\n",
    "print('1. 📊 Volatility Features:')\n",
    "volatility_windows = [10, 20, 30]\n",
    "for window in volatility_windows:\n",
    "    df_features[f'Volatility_{window}d'] = df_features['Daily_Return'].rolling(window=window).std()\n",
    "    df_features[f'Volatility_{window}d_Annualized'] = df_features[f'Volatility_{window}d'] * np.sqrt(252)\n",
    "print(f'   ✅ Volatility measures for windows {volatility_windows} created')\n",
    "\n",
    "# 2. Support and Resistance Levels\n",
    "print('2. 📊 Support and Resistance Features:')\n",
    "for window in [20, 50]:\n",
    "    df_features[f'Support_{window}d'] = df_features['Low'].rolling(window=window).min()\n",
    "    df_features[f'Resistance_{window}d'] = df_features['High'].rolling(window=window).max()\n",
    "    df_features[f'Support_Distance_{window}d'] = ((df_features['Close'] - df_features[f'Support_{window}d']) / df_features['Close']) * 100\n",
    "    df_features[f'Resistance_Distance_{window}d'] = ((df_features[f'Resistance_{window}d'] - df_features['Close']) / df_features['Close']) * 100\n",
    "print('   ✅ Support and resistance levels created')\n",
    "\n",
    "# 3. Momentum Features\n",
    "print('3. 📊 Momentum Features:')\n",
    "momentum_periods = [5, 10, 20]\n",
    "for period in momentum_periods:\n",
    "    df_features[f'Momentum_{period}d'] = df_features['Close'] - df_features['Close'].shift(period)\n",
    "    df_features[f'Momentum_{period}d_Pct'] = ((df_features['Close'] - df_features['Close'].shift(period)) / df_features['Close'].shift(period)) * 100\n",
    "print(f'   ✅ Momentum features for periods {momentum_periods} created')\n",
    "\n",
    "# 4. Rate of Change (ROC)\n",
    "print('4. 📊 Rate of Change Features:')\n",
    "roc_periods = [5, 10, 20]\n",
    "for period in roc_periods:\n",
    "    if TALIB_AVAILABLE:\n",
    "        df_features[f'ROC_{period}d'] = talib.ROC(df_features['Close'].values, timeperiod=period)\n",
    "    else:\n",
    "        df_features[f'ROC_{period}d'] = ((df_features['Close'] - df_features['Close'].shift(period)) / df_features['Close'].shift(period)) * 100\n",
    "print(f'   ✅ ROC features for periods {roc_periods} created')\n",
    "\n",
    "# 5. Price Channels\n",
    "print('5. 📊 Price Channel Features:')\n",
    "channel_periods = [10, 20]\n",
    "for period in channel_periods:\n",
    "    df_features[f'Upper_Channel_{period}d'] = df_features['High'].rolling(window=period).max()\n",
    "    df_features[f'Lower_Channel_{period}d'] = df_features['Low'].rolling(window=period).min()\n",
    "    df_features[f'Channel_Position_{period}d'] = ((df_features['Close'] - df_features[f'Lower_Channel_{period}d']) / \n",
    "                                                 (df_features[f'Upper_Channel_{period}d'] - df_features[f'Lower_Channel_{period}d'])) * 100\n",
    "print(f'   ✅ Price channel features for periods {channel_periods} created')\n",
    "\n",
    "print(f'\\n📊 Final features count: {df_features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a552ee",
   "metadata": {},
   "source": [
    "## 🎯 Target Variables for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('🎯 CREATING TARGET VARIABLES FOR MACHINE LEARNING')\n",
    "print('='*55)\n",
    "\n",
    "# 1. Price Prediction Targets\n",
    "print('1. 📊 Price Prediction Targets:')\n",
    "prediction_horizons = [1, 3, 5, 10, 20]\n",
    "for horizon in prediction_horizons:\n",
    "    df_features[f'Target_Price_{horizon}d'] = df_features['Close'].shift(-horizon)\n",
    "    df_features[f'Target_Return_{horizon}d'] = ((df_features['Close'].shift(-horizon) - df_features['Close']) / df_features['Close']) * 100\n",
    "print(f'   ✅ Price and return targets for horizons {prediction_horizons} created')\n",
    "\n",
    "# 2. Classification Targets\n",
    "print('2. 📊 Classification Targets:')\n",
    "for horizon in [1, 5, 10]:\n",
    "    # Binary classification: up/down\n",
    "    df_features[f'Target_Direction_{horizon}d'] = (df_features[f'Target_Return_{horizon}d'] > 0).astype(int)\n",
    "    \n",
    "    # Multi-class classification: strong_down, down, flat, up, strong_up\n",
    "    conditions = [\n",
    "        df_features[f'Target_Return_{horizon}d'] <= -2,\n",
    "        (df_features[f'Target_Return_{horizon}d'] > -2) & (df_features[f'Target_Return_{horizon}d'] <= -0.5),\n",
    "        (df_features[f'Target_Return_{horizon}d'] > -0.5) & (df_features[f'Target_Return_{horizon}d'] < 0.5),\n",
    "        (df_features[f'Target_Return_{horizon}d'] >= 0.5) & (df_features[f'Target_Return_{horizon}d'] < 2),\n",
    "        df_features[f'Target_Return_{horizon}d'] >= 2\n",
    "    ]\n",
    "    choices = [0, 1, 2, 3, 4]  # strong_down, down, flat, up, strong_up\n",
    "    df_features[f'Target_Class_{horizon}d'] = np.select(conditions, choices, default=2)\n",
    "print('   ✅ Binary and multi-class classification targets created')\n",
    "\n",
    "# 3. Volatility Targets\n",
    "print('3. 📊 Volatility Prediction Targets:')\n",
    "for horizon in [5, 10, 20]:\n",
    "    # Future volatility\n",
    "    future_returns = df_features['Daily_Return'].rolling(window=horizon).std().shift(-horizon)\n",
    "    df_features[f'Target_Volatility_{horizon}d'] = future_returns\n",
    "    \n",
    "    # High/Low volatility classification\n",
    "    vol_median = df_features[f'Target_Volatility_{horizon}d'].median()\n",
    "    df_features[f'Target_High_Vol_{horizon}d'] = (df_features[f'Target_Volatility_{horizon}d'] > vol_median).astype(int)\n",
    "print('   ✅ Volatility prediction targets created')\n",
    "\n",
    "print(f'\\n📊 Final dataset shape: {df_features.shape}')\n",
    "print(f'🎯 Total features created: {df_features.shape[1] - len(df.columns)} new features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5822c6",
   "metadata": {},
   "source": [
    "## 📋 Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('📋 FEATURE ENGINEERING SUMMARY')\n",
    "print('='*50)\n",
    "\n",
    "# Calculate feature categories\n",
    "feature_categories = {\n",
    "    'Original Features': len(df.columns),\n",
    "    'Price Features': len([col for col in df_features.columns if any(x in col.lower() for x in ['price', 'open', 'close', 'high', 'low', 'return', 'gap'])]),\n",
    "    'Moving Average Features': len([col for col in df_features.columns if any(x in col for x in ['SMA', 'EMA', 'MA_'])]),\n",
    "    'Technical Indicators': len([col for col in df_features.columns if any(x in col for x in ['RSI', 'MACD', 'BB_', 'Stoch', 'ATR'])]),\n",
    "    'Volume Features': len([col for col in df_features.columns if 'volume' in col.lower() or 'obv' in col.lower()]),\n",
    "    'Time Features': len([col for col in df_features.columns if any(x in col.lower() for x in ['year', 'month', 'day', 'quarter', 'sin', 'cos', 'is_'])]),\n",
    "    'Advanced Features': len([col for col in df_features.columns if any(x in col.lower() for x in ['volatility', 'momentum', 'roc', 'channel', 'support', 'resistance'])]),\n",
    "    'Target Variables': len([col for col in df_features.columns if col.startswith('Target_')]),\n",
    "    'Total Features': df_features.shape[1]\n",
    "}\n",
    "\n",
    "print('\\n📊 FEATURE BREAKDOWN:')\n",
    "for category, count in feature_categories.items():\n",
    "    print(f'   {category}: {count}')\n",
    "\n",
    "# Data quality check\n",
    "print('\\n🔍 DATA QUALITY CHECK:')\n",
    "missing_values = df_features.isnull().sum().sum()\n",
    "total_values = df_features.size\n",
    "completeness = ((total_values - missing_values) / total_values) * 100\n",
    "\n",
    "print(f'   Missing Values: {missing_values:,}')\n",
    "print(f'   Total Values: {total_values:,}')\n",
    "print(f'   Data Completeness: {completeness:.2f}%')\n",
    "print(f'   Memory Usage: {df_features.memory_usage(deep=True).sum() / 1024**2:.2f} MB')\n",
    "\n",
    "# Feature correlation analysis\n",
    "print('\\n📈 FEATURE CORRELATION ANALYSIS:')\n",
    "numeric_features = df_features.select_dtypes(include=[np.number]).columns\n",
    "high_corr_features = []\n",
    "\n",
    "if len(numeric_features) > 1:\n",
    "    corr_matrix = df_features[numeric_features].corr()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_pairs = [(column, index, upper_triangle.loc[index, column]) \n",
    "                      for column in upper_triangle.columns \n",
    "                      for index in upper_triangle.index \n",
    "                      if abs(upper_triangle.loc[index, column]) > 0.95 and not pd.isna(upper_triangle.loc[index, column])]\n",
    "    \n",
    "    print(f'   Highly Correlated Feature Pairs (>0.95): {len(high_corr_pairs)}')\n",
    "    if high_corr_pairs:\n",
    "        print('   Top 5 highly correlated pairs:')\n",
    "        for i, (col1, col2, corr) in enumerate(sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True)[:5]):\n",
    "            print(f'     {i+1}. {col1} - {col2}: {corr:.3f}')\n",
    "\n",
    "# Save feature-engineered dataset\n",
    "print('\\n💾 SAVING FEATURE-ENGINEERED DATASET:')\n",
    "output_file = '../data/TCS_stock_features.csv'\n",
    "df_features.to_csv(output_file, index=False)\n",
    "print(f'✅ Dataset saved: {output_file}')\n",
    "print(f'📊 Shape: {df_features.shape}')\n",
    "\n",
    "# Display sample of features\n",
    "print('\\n📋 SAMPLE OF ENGINEERED FEATURES:')\n",
    "sample_features = ['Date', 'Close', 'Daily_Return', 'RSI_14', 'MACD', 'BB_Position', \n",
    "                  'Volume_Ratio_20', 'SMA_20_ratio', 'Target_Return_1d', 'Target_Direction_1d']\n",
    "available_features = [col for col in sample_features if col in df_features.columns]\n",
    "display(df_features[available_features].tail(10))\n",
    "\n",
    "print('\\n✅ FEATURE ENGINEERING COMPLETED SUCCESSFULLY!')\n",
    "print('🔄 Next: Model Training (04_model_training.ipynb)')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
